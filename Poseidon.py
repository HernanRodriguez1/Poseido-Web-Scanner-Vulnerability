import argparse
import random
import requests
import threading
import yaml
import re

print('''\033[91m
========= ======== ======== ======== ======== ======== ========
=              Poseidon Web Scanner Vulnerability 1.0         =
=                                                             =
========= ======== Create By Hernan Rodriguez ======== ========
''')

# Crear argumentos para ingresar los valores hosts, cookie, hilos, y parámetro GET
parser = argparse.ArgumentParser(description='Realizar múltiples consultas HTTP y HTTPS con TLS y SSL')
parser.add_argument('-d', dest='hosts', type=str, help='Ruta del archivo con la lista de dominios')
parser.add_argument('-t', dest='hilos', type=int, help='Número de hilos a ser utilizados')
parser.add_argument('-q', dest='get_file', type=str, help='Ruta del archivo con la lista de valores GET')
parser.add_argument('-f', dest='config', type=str, help='Ruta del archivo de configuración YAML')
parser.add_argument('-c', dest='cookie', type=str, help='Valor de la cookie', default=None)
args = parser.parse_args()

# Leer el archivo YAML y concatenar las expresiones regulares en una cadena separadas por "|"
with open(args.config, 'r') as f:
    config = yaml.safe_load(f)
regex = '|'.join(config['extractors'][0]['regex'])

# Lista con dos User-Agents para ser utilizados de manera aleatoria
user_agents = ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3', 
              'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0']

# Función que realiza la consulta HTTP o HTTPS dependiendo de la URL
def realizar_consulta(url, get, cookie, respuestas_obtenidas):
    headers = {'User-Agent': random.choice(user_agents)}
    if cookie:
        headers['Cookie'] = cookie
        if not hasattr(realizar_consulta, 'cookie_impresa'):
            print(f'Using Cookie: {cookie} for all URLs'+'\n')
            realizar_consulta.cookie_impresa = True
    if url.startswith('https'):
        resp = requests.get(url, params=get, headers=headers, verify=False)
    else:
        resp = requests.get(url, params=get, headers=headers)
    if resp.status_code in [200, 500] and re.search(regex, resp.text):
        if resp.text not in respuestas_obtenidas:
            respuestas_obtenidas.add(resp.text)
            print(url)

# Función que crea los hilos y llama a la función realizar_consulta
def iniciar_hilos(hosts, hilos, get, cookie):
    with open(hosts) as f:
        urls = f.readlines()
    urls = [x.strip() for x in urls]
    threads = []
    respuestas_obtenidas = set()
    for url in urls:
        t = threading.Thread(target=realizar_consulta, args=(url, get, cookie, respuestas_obtenidas))
        threads.append(t)
        t.start()
    for t in threads:
        t.join()

if __name__ == '__main__':
    if args.get_file:
        with open(args.get_file, 'r') as f:
            get_values = f.readlines()
        get_values = [x.strip() for x in get_values]
        for get in get_values:
            iniciar_hilos(args.hosts, args.hilos, get, args.cookie)
    else:
        iniciar_hilos(args.hosts, args.hilos, args.get,args.cookie)
